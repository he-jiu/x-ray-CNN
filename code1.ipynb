{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='mps'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"./chest_xray/chest_xray_ternary/train\"\n",
    "data=[]\n",
    "for catagory in os.listdir(root):\n",
    "        if catagory=='.DS_Store':\n",
    "            continue\n",
    "        catagory_path=os.path.join(root,catagory)\n",
    "        for image in os.listdir(catagory_path):\n",
    "            image_path=os.path.join(catagory_path,image)\n",
    "            data.append((Image.open(image_path).width,Image.open(image_path).height))\n",
    "x = np.array([i[0] for i in data])\n",
    "y = np.array([i[1] for i in data])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x, y, alpha=0.3,marker='.',)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class X_ray(Dataset):\n",
    "    def __init__(self,root,transform):\n",
    "        self.root=root\n",
    "        self.transform = transform\n",
    "        self.data=[]\n",
    "        self.namelabel={\"BACTERIAL\":0,\"NORMAL\":1,\"VIRAL\":2}\n",
    "\n",
    "        for catagory in os.listdir(root):\n",
    "            if catagory=='.DS_Store':\n",
    "                continue\n",
    "            catagory_path=os.path.join(root,catagory)\n",
    "            for image in os.listdir(catagory_path):\n",
    "                image_path=os.path.join(catagory_path,image)\n",
    "                self.data.append((image_path,catagory))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = self.data[idx][0]\n",
    "     \n",
    "        # Use PIL for image loading\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        # Apply the transformations\n",
    "        tensor_image = self.transform(image)\n",
    "\n",
    "        target=torch.tensor(int(self.namelabel[self.data[idx][1]]))\n",
    "        \n",
    "        return tensor_image.to(device),target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnsfrm = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_vaild_set=X_ray(\n",
    "    root='./chest_xray/chest_xray_ternary/train',\n",
    "    transform=trnsfrm\n",
    ")\n",
    "\n",
    "train_num = int(len(train_vaild_set)*0.7)+1\n",
    "valid_num = int(len(train_vaild_set)*0.3)\n",
    "\n",
    "\n",
    "train_set,valid_set=torch.utils.data.random_split(\n",
    "    train_vaild_set,\n",
    "    lengths=[train_num,valid_num],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "valid_loader=torch.utils.data.DataLoader(\n",
    "    valid_set,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.vgg16(pretrained=False).to(device)\n",
    "model.classifier._modules['6'] = nn.Linear(4096,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(valid_loader,net):\n",
    "    net=net.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_valid_loss = 0\n",
    "    n = 0    # counter for number of minibatches\n",
    "    with torch.no_grad():           #valid\n",
    "        for data in valid_loader:\n",
    "            img,target = data\n",
    "            outputs = net(img)\n",
    "            loss = loss_fn(outputs,target)\n",
    "            total_valid_loss += loss.item()\n",
    "            n+=1\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)    # add in the number of labels in this batch\n",
    "        correct += (predicted == target).sum().item()  # add in the number of correct labels\n",
    "\n",
    "        # collect together statistics for this epoch\n",
    "\n",
    "        lvld = total_valid_loss/n\n",
    "        avld = correct/total\n",
    "    return lvld,avld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training(train_loader,valid_loader,net,nepochs):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    statsrec = np.zeros((4,nepochs))    \n",
    "    net=net.to(device)\n",
    "    for epoch in range(nepochs): \n",
    "        print(\"------------epoch:{d}------------\".format(epoch+1)) \n",
    "        correct=0            # number of examples predicted correctly (for accuracy) \n",
    "        total = 0            # number of examples\n",
    "        running_loss = 0.0   # accumulated loss (for mean loss)\n",
    "        n = 0                # number of minibatches\n",
    "        for data in tqdm(train_loader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward, backward, and update parameters\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # accumulate data for accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)    # add in the number of labels in this minibatch\n",
    "            correct += (predicted == labels).sum().item()  # add in the number of correct labels\n",
    "\n",
    "            n += 1\n",
    "            # if n%100 == 0:\n",
    "            #     print('Numbers of training:{}, Loss:{:.3f}'.format(n,loss))\n",
    "\n",
    "        ltrn = running_loss/n\n",
    "        atrn = correct/total \n",
    "\n",
    "        lvld, avld=valid(valid_loader,net)\n",
    "\n",
    "        statsrec[:,epoch] = (ltrn, atrn, lvld, avld)\n",
    "\n",
    "        print('accurancy of train:{:.1%}, accurancy of validation:{:.1%}'.format(atrn,avld))\n",
    "\n",
    "    return statsrec\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=5\n",
    "Training_statsrec=Training(train_loader,valid_loader,model,nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=50\n",
    "Training_statsrec=Training(train_loader,valid_loader,model,nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrn=gaussian_filter1d(Training_statsrec[0],sigma=2)\n",
    "lvld=gaussian_filter1d(Training_statsrec[2],sigma=2)\n",
    "\n",
    "x=[i for i in range(50)]\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.plot(x, ltrn,label='ltrn') \n",
    "plt.plot(x, lvld,label='lvld') \n",
    "plt.legend()\n",
    "\n",
    "atrn=gaussian_filter1d(Training_statsrec[1],sigma=2)\n",
    "avld=gaussian_filter1d(Training_statsrec[3],sigma=2)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.plot(x, atrn,label='atrn')\n",
    "plt.plot(x, avld,label='avld') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pred(model,loader,categories_names):\n",
    "    all_preds=torch.tensor([])\n",
    "    all_targets=torch.tensor([])\n",
    "    i=0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            images,label=batch\n",
    "            preds=model(images)\n",
    "            \n",
    "            all_preds=torch.cat((all_preds,preds),dim=0)\n",
    "            all_targets=torch.cat((all_targets,label),dim=0)\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        cm=confusion_matrix(all_targets.tolist(),all_preds.argmax(dim=1).tolist())\n",
    "        conf_matrix=pd.DataFrame(data=cm,columns=categories_names\n",
    "                                          ,index=categories_names)\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\",cmap='gray')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_names=[\"BACTERIAL\",\"NORMAL\",\"VIRAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_pred(model,train_loader,categories_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_pred(model,valid_loader,categories_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testSet(Dataset):\n",
    "    def __init__(self,root,transform):\n",
    "        self.root=root\n",
    "        self.transform = transform\n",
    "        self.data=[]\n",
    "        self.namelabel={\"BACTERIAL\":0,\"NORMAL\":1,\"VIRAL\":2}\n",
    "\n",
    "\n",
    "        for catagory in os.listdir(root):\n",
    "            if catagory=='.DS_Store':\n",
    "                continue\n",
    "            catagory_path=os.path.join(root,catagory)\n",
    "            for image in os.listdir(catagory_path):\n",
    "                image_path=os.path.join(catagory_path,image)\n",
    "                self.data.append((image_path,catagory))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = self.data[idx][0]\n",
    "     \n",
    "        # Use PIL for image loading\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        # Apply the transformations\n",
    "        tensor_image = self.transform(image)\n",
    "        label = torch.tensor(self.namelabel[self.data[idx][1]])\n",
    "        return tensor_image, label\n",
    "\n",
    "trnsfrm = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_set=testSet(\n",
    "    root='./chest_xray/chest_xray_ternary/test',\n",
    "    transform=trnsfrm\n",
    ")\n",
    "test_loader=torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=64,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'net.pth')\n",
    "test_model=models.vgg16(pretrained=False)\n",
    "test_model.classifier._modules['6'] = nn.Linear(4096,3)\n",
    "test_model.load_state_dict(torch.load('net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_pred(test_model,test_loader,categories_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
